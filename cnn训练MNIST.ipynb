{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0 Training Accuracy=0.0957, Testing Accuracy=0.1017\n",
      "Iter 100 Training Accuracy=0.6361, Testing Accuracy=0.64\n",
      "Iter 200 Training Accuracy=0.7419, Testing Accuracy=0.7512\n",
      "Iter 300 Training Accuracy=0.8209, Testing Accuracy=0.8298\n",
      "Iter 400 Training Accuracy=0.8437, Testing Accuracy=0.8515\n",
      "Iter 500 Training Accuracy=0.8544, Testing Accuracy=0.8595\n",
      "Iter 600 Training Accuracy=0.8616, Testing Accuracy=0.8647\n",
      "Iter 700 Training Accuracy=0.9382, Testing Accuracy=0.9434\n",
      "Iter 800 Training Accuracy=0.9551, Testing Accuracy=0.9544\n",
      "Iter 900 Training Accuracy=0.9569, Testing Accuracy=0.9617\n",
      "Iter 1000 Training Accuracy=0.9577, Testing Accuracy=0.959\n",
      "Iter 1100 Training Accuracy=0.9647, Testing Accuracy=0.9689\n",
      "Iter 1200 Training Accuracy=0.9668, Testing Accuracy=0.9677\n",
      "Iter 1300 Training Accuracy=0.9679, Testing Accuracy=0.9705\n",
      "Iter 1400 Training Accuracy=0.9616, Testing Accuracy=0.9649\n",
      "Iter 1500 Training Accuracy=0.9692, Testing Accuracy=0.9715\n",
      "Iter 1600 Training Accuracy=0.9716, Testing Accuracy=0.9742\n",
      "Iter 1700 Training Accuracy=0.9702, Testing Accuracy=0.9734\n",
      "Iter 1800 Training Accuracy=0.9747, Testing Accuracy=0.974\n",
      "Iter 1900 Training Accuracy=0.9743, Testing Accuracy=0.9753\n",
      "Iter 2000 Training Accuracy=0.9767, Testing Accuracy=0.976\n",
      "Iter 2100 Training Accuracy=0.978, Testing Accuracy=0.9783\n",
      "Iter 2200 Training Accuracy=0.9781, Testing Accuracy=0.9755\n",
      "Iter 2300 Training Accuracy=0.9797, Testing Accuracy=0.9778\n",
      "Iter 2400 Training Accuracy=0.9792, Testing Accuracy=0.9789\n",
      "Iter 2500 Training Accuracy=0.9786, Testing Accuracy=0.9786\n",
      "Iter 2600 Training Accuracy=0.9782, Testing Accuracy=0.9766\n",
      "Iter 2700 Training Accuracy=0.9814, Testing Accuracy=0.9804\n",
      "Iter 2800 Training Accuracy=0.9813, Testing Accuracy=0.9804\n",
      "Iter 2900 Training Accuracy=0.9813, Testing Accuracy=0.9808\n",
      "Iter 3000 Training Accuracy=0.9809, Testing Accuracy=0.9812\n",
      "Iter 3100 Training Accuracy=0.9803, Testing Accuracy=0.9802\n",
      "Iter 3200 Training Accuracy=0.9803, Testing Accuracy=0.9818\n",
      "Iter 3300 Training Accuracy=0.98, Testing Accuracy=0.9831\n",
      "Iter 3400 Training Accuracy=0.98, Testing Accuracy=0.9838\n",
      "Iter 3500 Training Accuracy=0.9839, Testing Accuracy=0.9831\n",
      "Iter 3600 Training Accuracy=0.9842, Testing Accuracy=0.9858\n",
      "Iter 3700 Training Accuracy=0.9845, Testing Accuracy=0.9846\n",
      "Iter 3800 Training Accuracy=0.9839, Testing Accuracy=0.9833\n",
      "Iter 3900 Training Accuracy=0.9874, Testing Accuracy=0.9855\n",
      "Iter 4000 Training Accuracy=0.9846, Testing Accuracy=0.9844\n",
      "Iter 4100 Training Accuracy=0.9865, Testing Accuracy=0.9852\n",
      "Iter 4200 Training Accuracy=0.9851, Testing Accuracy=0.9858\n",
      "Iter 4300 Training Accuracy=0.9852, Testing Accuracy=0.9859\n",
      "Iter 4400 Training Accuracy=0.9878, Testing Accuracy=0.9861\n",
      "Iter 4500 Training Accuracy=0.9866, Testing Accuracy=0.987\n",
      "Iter 4600 Training Accuracy=0.9856, Testing Accuracy=0.9852\n",
      "Iter 4700 Training Accuracy=0.9874, Testing Accuracy=0.9871\n",
      "Iter 4800 Training Accuracy=0.9887, Testing Accuracy=0.9869\n",
      "Iter 4900 Training Accuracy=0.9866, Testing Accuracy=0.9871\n",
      "Iter 5000 Training Accuracy=0.9881, Testing Accuracy=0.9875\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('data', one_hot=True)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 128\n",
    "num_step = 5001\n",
    "\n",
    "def weigth_variable(shape, name):\n",
    "    return tf.Variable(tf.truncated_normal(dtype=tf.float32, shape= shape, stddev=0.1), name=name)\n",
    "\n",
    "def biase_varibale(shape, name):\n",
    "    #return tf.Variable(tf.zeros(shape=shape) + 0.1)\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape), name=name)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(input=x, filter=W, strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(value=x, ksize=[1,2,2,1], strides= [1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "def variables_summaries(var):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar('mean', mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar('stddev', stddev)\n",
    "    tf.summary.scalar('max', tf.reduce_max(var))\n",
    "    tf.summary.scalar('min', tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram', var)\n",
    "    \n",
    "#输入\n",
    "with tf.name_scope(name = 'input'):\n",
    "    with tf.name_scope(name = 'input_x'):\n",
    "        x = tf.placeholder(dtype=tf.float32, shape=[None, 784])\n",
    "    with tf.name_scope(name = 'input_y'):\n",
    "        y = tf.placeholder(dtype=tf.float32, shape=[None, 10])\n",
    "    with tf.name_scope(name = 'keep_prob'):\n",
    "        keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "    with tf.name_scope(name = 'image_x'):\n",
    "        image_x = tf.reshape(x, shape=[-1,28,28,1], name = 'image_x')\n",
    "         \n",
    "with tf.name_scope('Conv1'):\n",
    "    #初始化第一个卷积层的权值和偏置值\n",
    "    with tf.name_scope('W_Conv1'):\n",
    "        W_Conv1 = weigth_variable([5,5,1,32], name='W_Conv1')\n",
    "        variables_summaries(W_Conv1)\n",
    "    with tf.name_scope('b_Conv1'):       \n",
    "        b_Conv1 = biase_varibale([32], name='b_Conv1')\n",
    "        variables_summaries(b_Conv1)\n",
    "    #把image和权值向量卷积，再加上偏置值，然后应用relu激活函数，最后加上池化层\n",
    "    with tf.name_scope('conv2d_1'):\n",
    "        conv2d_1 = conv2d(image_x, W_Conv1) + b_Conv1\n",
    "    with tf.name_scope('relu_1'):\n",
    "        h_conv1 = tf.nn.relu(conv2d_1, name='relu_1')\n",
    "    with tf.name_scope('pool_1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "        \n",
    "with tf.name_scope('Conv2'):\n",
    "    #初始化第二个卷积层的权值和偏置值\n",
    "    with tf.name_scope('W_Conv2'):\n",
    "        W_Conv2 = weigth_variable([5,5,32,64], name='W_Conv2')\n",
    "        variables_summaries(W_Conv2)\n",
    "    with tf.name_scope('b_Conv2'):\n",
    "        b_Conv2 = biase_varibale([64], name = 'b_Conv2')\n",
    "        variables_summaries(b_Conv2)\n",
    "        \n",
    "    #把h_pool1和权值向量卷积，再加上偏置值，然后应用relu激活函数，最后加上池化层\n",
    "    with tf.name_scope('conv2d_2'):\n",
    "        conv2d_2 = conv2d(h_pool1, W_Conv2) + b_Conv2\n",
    "    with tf.name_scope('relu2'):\n",
    "        h_conv2 = tf.nn.relu(conv2d_2, name = 'relu2')\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "with tf.name_scope('fc1'):\n",
    "    #初始化第一个全连接层权值\n",
    "    with tf.name_scope('W_fc1'):\n",
    "        W_fc1 = weigth_variable(shape=[7*7*64, 1024], name='W_fc1')\n",
    "        variables_summaries(W_fc1)\n",
    "    with tf.name_scope('b_fc1'):\n",
    "        b_fc1 = biase_varibale(shape=[1024], name='b_fc1')\n",
    "        variables_summaries(b_fc1)\n",
    "        \n",
    "    #h_pool2扁平化\n",
    "    with tf.name_scope('h_pool2_flat'):\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64], name='h_pool2_flat')\n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        fc1 = tf.matmul(h_pool2_flat, W_fc1) + b_fc1\n",
    "    with tf.name_scope('relu'):\n",
    "        fc1_relu = tf.nn.relu(fc1, name='relu')\n",
    "    with tf.name_scope('fc1_dropout'):\n",
    "        fc1_drop = tf.nn.dropout(fc1_relu, keep_prob=keep_prob)\n",
    "    \n",
    "with tf.name_scope('fc2'):\n",
    "    #初始化第二个全连接层权值\n",
    "    with tf.name_scope('W_fc2'):\n",
    "        W_fc2 = weigth_variable(shape=[1024, 10], name='W_fc2')\n",
    "        variables_summaries(W_fc2)\n",
    "    with tf.name_scope('b_fc2'):\n",
    "        b_fc2 = weigth_variable(shape=[10], name='b_fc2')\n",
    "        variables_summaries(b_fc2)\n",
    "        \n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        fc2 = tf.matmul(fc1_drop, W_fc2) + b_fc2\n",
    "    with tf.name_scope('relu'):\n",
    "        fc2_relu = tf.nn.relu(fc2)\n",
    "    with tf.name_scope('fc2_dropout'):\n",
    "        fc2_drop = tf.nn.dropout(fc2_relu, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope('fc3'):\n",
    "    with tf.name_scope('W_fc3'):\n",
    "        W_fc3 = weigth_variable(shape=[10,10], name='W_fc3')\n",
    "        variables_summaries(W_fc3)\n",
    "    with tf.name_scope('b_fc3'):\n",
    "        b_fc3 = biase_varibale(shape=[10], name='b_fc3')\n",
    "        variables_summaries(b_fc3)\n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        fc3 = tf.matmul(fc2_drop, W_fc3) + b_fc3\n",
    "    \n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction = tf.nn.softmax(fc3, name = 'softmax')\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction,name='loss'))\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correction_prediction'):\n",
    "        correction_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,1),name='correction_prediction')\n",
    "    \n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correction_prediction, dtype=tf.float32), name='accuracy')\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver()\n",
    "    train_writer = tf.summary.FileWriter('cnn_logs/train', graph=sess.graph)\n",
    "    test_writer = tf.summary.FileWriter('cnn_logs/test', graph=sess.graph)\n",
    " \n",
    "    for epoch in range(num_step):\n",
    "        xs_batch, ys_batch = mnist.train.next_batch(batch_size)     \n",
    "        summary, _ = sess.run([merged,train_step], feed_dict={x:xs_batch, y:ys_batch, keep_prob:0.8})\n",
    "        sess.run(train_step, feed_dict={x:xs_batch, y:ys_batch, keep_prob:0.8})\n",
    "        train_writer.add_summary(summary, epoch)\n",
    "        \n",
    "        xs_batch, ys_batch = mnist.test.next_batch(batch_size) \n",
    "        summary = sess.run(merged, feed_dict={x:xs_batch, y:ys_batch, keep_prob:1.0})\n",
    "        test_writer.add_summary(summary, epoch)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            test_acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels, keep_prob:1.0})\n",
    "            train_acc = sess.run(accuracy, feed_dict={x:mnist.train.images[:10000], y:mnist.train.labels[:10000], keep_prob:1.0})\n",
    "            print('Iter ' + str(epoch) + ' Training Accuracy=' + str(train_acc) +', Testing Accuracy=' + str(test_acc))\n",
    "            #print('Iter ' + str(epoch) +' Testing Accuracy=' + str(test_acc))\n",
    "    saver.save(sess=sess, save_path='model.ckpt')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
